y_hat <- as.numeric(y_hat)-1
misclass_rf <- sum(abs(y_true - y_hat))/length(y_hat)
misclass_rf # 0
model.control <- rpart.control(minsplit = 5, xval = 10, cp = 0)
cart_model <- rpart(diabetes ~ ., data = train_data, method = "class",
control = model.control)
model.control <- rpart.control(minsplit = 5, xval = 10, cp = 0)
cart_model <- rpart(classdigit ~ ., data = train_data, method = "class",
control = model.control)
# Model the full single tree
x11()
plot(fit)
# Model the full single tree
x11()
plot(cart_model)
text(cart_model, use.n = TRUE, cex = .5)
# Prune the tree back
min_cp = which.min(cart_model$cptable[,4])
x11()
plot(cart_model$cptable[,4], main = "Cp for model selection", ylab = "cv error")
pruned_fit <- prune(cart_model, cp = fit$cptable[min_cp, 1])
pruned_fit <- prune(cart_model, cp = cart_model$cptable[min_cp, 1])
x11()
plot(pruned_fit)
text(pruned_fit, use.n = TRUE, cex = .5)
# Compute test error for a single tree
my_pred <- predict(cart_model, newdata = test_data, type = "class")
y_true <- as.numeric(test_data$classdigit)-1
y_hat <- as.numeric(my_pred)-1
misclass_tree <- sum(abs(y_true- y_hat))/length(y_hat)
misclass_tree #
my_pred <- predict(cart_model, newdata = test_data, type = "class")
my_pred
my_pred <- predict(cart_model, newdata = test_data, type = "class")
y_true <- as.numeric(test_data$classdigit)
y_hat <- as.numeric(my_pred)
misclass_tree <- sum(abs(y_true- y_hat))/length(y_hat)
misclass_tree # 0
y_true <- as.numeric(test_data$classdigit)
y_true
y_true <- as.numeric(test_data$classdigit)
y_hat <- predict(boost.fit, newdata = test_data, type = "response")
y_hat <- as.numeric(y_hat)
misclass_boost <- sum(abs(y_true - y_hat))/length(y_hat)
misclass_boost # 0.33125
y_hat <- predict(rf.fit, newdata = test_data, type = "response")
y_hat <- as.numeric(y_hat)
misclass_rf <- sum(abs(y_true - y_hat))/length(y_hat)
misclass_rf # 0
misclass_tree # 0
y_true_boost <- as.numeric(test_data$classdigit)-1
y_true_boost <- as.numeric(test_data$classdigit)-1
y_hat_boost <- predict(boost.fit, newdata = test_data, type = "response")
y_hat_boost <- as.numeric(y_hat_boost)-1
misclass_boost <- sum(abs(y_true_boost - y_hat_boost))/length(y_hat_boost)
misclass_boost # 0.33125
rf.fit <- randomForest(classdigit ~ ., data = train_data, n.tree = 10000)
x11()
varImpPlot(rf.fit)
importance(rf.fit)
summary(rf.fit)
y_true_rf <- as.numeric(test_data$classdigit)-1
y_true_rf <- as.numeric(test_data$classdigit)-1
y_hat_rf <- predict(rf.fit, newdata = test_data, type = "response")
y_hat_rf <- as.numeric(y_hat_rf)-1
misclass_rf <- sum(abs(y_true_rf - y_hat_rf))/length(y_hat_rf)
misclass_rf # 0
rf.fit <- randomForest(classdigit ~ ., data = train_data, n.tree = 10000)
y_true_rf <- as.numeric(test_data$classdigit)-1
y_hat_rf <- predict(rf.fit, newdata = test_data, type = "response")
y_hat_rf <- as.numeric(y_hat_rf)-1
misclass_rf <- sum(abs(y_true_rf - y_hat_rf))/length(y_hat_rf)
misclass_rf # 0
y_true_rf <- as.numeric(test_data$classdigit)
y_hat_rf <- predict(rf.fit, newdata = test_data, type = "response")
y_hat_rf <- as.numeric(y_hat_rf)
misclass_rf <- sum(abs(y_true_rf - y_hat_rf))/length(y_hat_rf)
misclass_rf # 0
# Random Forest
rf.fit <- randomForest(classdigit ~ ., data = train_data, n.tree = 100)
x11()
varImpPlot(rf.fit)
importance(rf.fit)
summary(rf.fit)
y_true_rf <- as.numeric(test_data$classdigit)
y_hat_rf <- predict(rf.fit, newdata = test_data, type = "response")
y_hat_rf <- as.numeric(y_hat_rf)
misclass_rf <- sum(abs(y_true_rf - y_hat_rf))/length(y_hat_rf)
misclass_rf # 0
set.seed(123)
train_indices <- sample(1:nrow(pima), 0.7 * nrow(pima))
train_data <- pima[train_indices, ]
test_data <- pima[-train_indices, ]
rf.fit <- randomForest(classdigit ~ ., data = train_data, n.tree = 100)
x11()
varImpPlot(rf.fit)
importance(rf.fit)
summary(rf.fit)
y_true_rf <- as.numeric(test_data$classdigit)
y_hat_rf <- predict(rf.fit, newdata = test_data, type = "response")
y_hat_rf <- as.numeric(y_hat_rf)
misclass_rf <- sum(abs(y_true_rf - y_hat_rf))/length(y_hat_rf)
misclass_rf # 0
set.seed(123)
train_indices <- sample(1:nrow(pima), 0.7 * nrow(pima))
train_data <- pima[train_indices, ]
test_data <- pima[-train_indices, ]
boost.train <- train_data
boost.test <- test_data
boost.fit <- gbm(classdigit ~ .,
data = boost.train, n.trees = 1000, shrinkage = .1,
interaction.depth = 3, distribution = "adaboost")
summary(boost.fit)
y_true_boost <- test_data$classdigit-1
y_true_boost <- as.numeric(test_data$classdigit)-1
y_hat_boost <- predict(boost.fit, newdata = test_data, type = "response")
y_hat_boost <- y_hat_boost-1
misclass_boost <- sum(abs(y_true_boost - y_hat_boost))/length(y_hat_boost)
misclass_boost # 0.33125
rf.fit <- randomForest(classdigit ~ ., data = train_data, n.tree = 100)
y_true_rf <- as.numeric(test_data$classdigit)
y_hat_rf <- predict(rf.fit, newdata = test_data, type = "response")
y_hat_rf <- y_hat_rf-1
misclass_rf <- sum(abs(y_true_rf - y_hat_rf))/length(y_hat_rf)
misclass_rf # 0
y_true_rf <- as.numeric(test_data$classdigit)
y_hat_rf <- predict(rf.fit, newdata = test_data, type = "response")
y_hat_rf <- y_hat_rf-1
y_true_rf <- as.numeric(test_data$classdigit)
y_hat_rf <- predict(rf.fit, newdata = test_data, type = "response")
y_hat_rf <- as.numeric(y_hat_rf)-1
misclass_rf <- sum(abs(y_true_rf - y_hat_rf))/length(y_hat_rf)
misclass_rf # 0
y_true_rf <- as.numeric(test_data$classdigit)-1
y_hat_rf <- predict(rf.fit, newdata = test_data, type = "response")
y_hat_rf <- as.numeric(y_hat_rf)-1
misclass_rf <- sum(abs(y_true_rf - y_hat_rf))/length(y_hat_rf)
misclass_rf # 0
y_hat_rf <- predict(rf.fit, newdata = test_data, type = "response")
y_hat_rf <- as.numeric(y_hat_rf)
y_hat_rf <- as.numeric(y_hat_rf)-1
View(pima)
model.control <- rpart.control(minsplit = 5, xval = 10, cp = 0)
cart_model <- rpart(classdigit ~ ., data = train_data, method = "class",
control = model.control)
my_pred <- predict(cart_model, newdata = test_data, type = "class")
y_true <- as.numeric(test_data$classdigit)-1
my_pred_cart <- predict(cart_model, newdata = test_data, type = "class")
y_true_cart <- as.numeric(test_data$classdigit)-1
y_hat_cart <- as.numeric(my_pred_cart)-1
misclass_cart <- sum(abs(y_true- y_hat))/length(y_hat)
misclass_cart # 0
misclass_cart #
#######################################################
# Homework 4 Question 2
# ADS-635: Data Mining I
# Alison Croteau
# Created: 10/24/2023
# Modified: ---
#######################################################
# Install and import necessary libraries
library(rpart) # trees
library(gbm) # boosting
library(randomForest) # RF / bagging
library(ISLR)
library(class) #kNN
# Initialize workspace
rm(list = ls())
setwd("C:\\Users\\acrot\\OneDrive\\Documents\\ADS-635")
# Import the downloaded RData
head(pima)
# Install and import necessary libraries
library(rpart) # trees
library(gbm) # boosting
library(randomForest) # RF / bagging
library(ISLR)
library(class) #kNN
load("~/ADS-635/pima.RData")
# Split into test and training
set.seed(123)
train_indices <- sample(1:nrow(pima), 0.7 * nrow(pima))
train_data <- pima[train_indices, ]
test_data <- pima[-train_indices, ]
# Boosting
boost.train <- train_data
boost.test <- test_data
boost.fit <- gbm(classdigit ~ .,
data = boost.train, n.trees = 1000, shrinkage = .1,
interaction.depth = 3, distribution = "adaboost")
summary(boost.fit)
y_true_boost <- as.numeric(test_data$classdigit)-1
y_hat_boost <- predict(boost.fit, newdata = test_data, type = "response")
y_hat_boost <- y_hat_boost-1
misclass_boost <- sum(abs(y_true_boost - y_hat_boost))/length(y_hat_boost)
misclass_boost # 0.33125
# Random Forest
rf.fit <- randomForest(classdigit ~ ., data = train_data, n.tree = 100)
x11()
varImpPlot(rf.fit)
importance(rf.fit)
summary(rf.fit)
y_true_rf <- as.numeric(test_data$classdigit)-1
y_hat_rf <- predict(rf.fit, newdata = test_data, type = "response")
y_hat_rf <- as.numeric(y_hat_rf)-1
misclass_rf <- sum(abs(y_true_rf - y_hat_rf))/length(y_hat_rf)
misclass_rf # 0
# Single CART Model
model.control <- rpart.control(minsplit = 5, xval = 10, cp = 0)
cart_model <- rpart(classdigit ~ ., data = train_data, method = "class",
control = model.control)
# Compute test error for a single tree
my_pred_cart <- predict(cart_model, newdata = test_data, type = "class")
y_true_cart <- as.numeric(test_data$classdigit)-1
y_hat_cart <- as.numeric(my_pred_cart)-1
misclass_cart <- sum(abs(y_true- y_hat))/length(y_hat)
my_pred_cart <- predict(cart_model, newdata = test_data, type = "class")
y_true_cart <- as.numeric(test_data$classdigit)-1
y_hat_cart <- as.numeric(my_pred_cart)-1
misclass_cart <- sum(abs(y_true_cart - y_hat_cart))/length(y_hat_cart)
misclass_cart #
pred_boosting <- predict(boost.fit, as.matrix(test_data[, -9]))
confusionMatrix(as.factor(y_hat_boost), as.factor(test_data$diabetes))
library(caret) # confusion matrix
confusionMatrix(as.factor(y_hat_boost), as.factor(test_data$diabetes))
View(test_data)
install.packages("pdp")
library(pdp)
load("~/ADS-635/pima.RData")
rf.fit_importance <- importance(rf.fit)
top_vars <- rownames(rf.fit_importance)[order(-rf.fit_importance
[, "MeanDecreaseGini"])[1:2]]
pd_rf <- partial(rf.fit, pred.var = top_vars[1], grid.resolution = 20)
plotPartial(pd_rf, main = top_vars[1])
# For Boosting
boost.fit_importance <- importance(boost.fit)
cart_model_importance <- importance(cart_model)
y_true_boost <- as.numeric(test_data$classdigit)-1
y_hat_boost <- predict(boost.fit, newdata = test_data, type = "response")
ifelse(y_hat_boost > 0.5, 1, 0)
y_hat_boost <- y_hat_boost-1
misclass_boost <- sum(abs(y_true_boost - y_hat_boost))/length(y_hat_boost)
misclass_boost # 0.33125
y_hat_boost <- ifelse(y_hat_boost > 0.5, 1, 0)
y_hat_boost <- y_hat_boost-1
misclass_boost <- sum(abs(y_true_boost - y_hat_boost))/length(y_hat_boost)
misclass_boost # 0.33125
y_true_boost <- as.numeric(test_data$classdigit)-1
y_hat_boost <- predict(boost.fit, newdata = test_data, type = "response")
y_hat_boost <- ifelse(y_hat_boost > 0.5, 1, 0)
misclass_boost <- sum(abs(y_true_boost - y_hat_boost))/length(y_hat_boost)
misclass_boost # 0.33125
y_true_boost <- as.numeric(test_data$classdigit)
y_hat_boost <- predict(boost.fit, newdata = test_data, type = "response")
y_hat_boost <- ifelse(y_hat_boost > 0.5, 1, 0)
misclass_boost <- sum(abs(y_true_boost - y_hat_boost))/length(y_hat_boost)
misclass_boost # 0.33125
y_true_boost <- as.numeric(test_data$classdigit)-1
y_hat_boost <- predict(boost.fit, newdata = test_data, type = "response")
y_hat_boost <- ifelse(y_hat_boost > 0.5, 1, 0)
misclass_boost <- sum(abs(y_true_boost - y_hat_boost))/length(y_hat_boost)
misclass_boost # 0.33125
y_hat_boost <- ifelse(y_hat_boost > 0.5, 1, 0)-1
y_true_boost <- as.numeric(test_data$classdigit)-1
y_hat_boost <- predict(boost.fit, newdata = test_data, type = "response")
y_hat_boost <- ifelse(y_hat_boost > 0.5, 1, 0)-1
misclass_boost <- sum(abs(y_true_boost - y_hat_boost))/length(y_hat_boost)
misclass_boost # 0.33125
# Random Forest
rf.fit <- randomForest(classdigit ~ ., data = train_data, ntree = 100)
x11()
varImpPlot(rf.fit)
importance(rf.fit)
summary(rf.fit)
y_true_rf <- as.numeric(test_data$classdigit)-1
y_hat_rf <- predict(rf.fit, newdata = test_data, type = "response")
y_hat_rf <- as.numeric(y_hat_rf)-1
misclass_rf <- sum(abs(y_true_rf - y_hat_rf))/length(y_hat_rf)
misclass_rf # 0
y_true_rf <- as.numeric(test_data$classdigit)-1
y_hat_rf <- predict(rf.fit, newdata = test_data, type = "response")
y_hat_rf <- ifelse(y_hat_rf > 0.5, 1, 0)-1
misclass_rf <- sum(abs(y_true_rf - y_hat_rf))/length(y_hat_rf)
misclass_rf # 0
y_true_rf <- as.numeric(test_data$classdigit)-1
y_hat_rf <- predict(rf.fit, newdata = test_data, type = "response")
y_hat_rf <- as.numeric(y_hat_rf)-1
misclass_rf <- sum(abs(y_true_rf - y_hat_rf))/length(y_hat_rf)
misclass_rf # 0
model.control <- rpart.control(minsplit = 5, xval = 10, cp = 0)
cart_model <- rpart(classdigit ~ ., data = train_data, method = "class",
control = model.control)
my_pred_cart <- predict(cart_model, newdata = test_data, type = "class")
y_true_cart <- as.numeric(test_data$classdigit)-1
y_hat_cart <- as.numeric(my_pred_cart)-1
misclass_cart <- sum(abs(y_true_cart - y_hat_cart))/length(y_hat_cart)
misclass_cart # 0
summary(boot.fit)
summary(boost.fit)
# For CART
x11()
plot(cart_model)
text(cart_model, use.n = TRUE, cex = .5)
boost.train <- train_data
boost.test <- test_data
boost.fit <- gbm(classdigit ~ npregnant + glucose + diastolic.bp +
skinfold.thickness + bmi + pedigree + age,
data = boost.train, n.trees = 1000,
shrinkage = .1, interaction.depth = 3, distribution = "adaboost")
summary(boost.fit)
y_true_boost <- as.numeric(test_data$classdigit)-1
y_hat_boost <- predict(boost.fit, newdata = test_data, type = "response")
y_hat_boost <- ifelse(y_hat_boost > 0.5, 1, 0)-1
misclass_boost <- sum(abs(y_true_boost - y_hat_boost))/length(y_hat_boost)
misclass_boost # 0.33125
rf.fit <- randomForest(classdigit ~ npregnant + glucose + diastolic.bp +
skinfold.thickness + bmi + pedigree + age,
data = train_data, ntree = 100)
varImpPlot(rf.fit)
importance(rf.fit)
summary(rf.fit)
importance(rf.fit)
y_true_rf <- as.numeric(test_data$classdigit)-1
y_hat_rf <- predict(rf.fit, newdata = test_data, type = "response")
y_hat_rf <- as.numeric(y_hat_rf)-1
misclass_rf <- sum(abs(y_true_rf - y_hat_rf))/length(y_hat_rf)
misclass_rf # 0
model.control <- rpart.control(minsplit = 5, xval = 10, cp = 0)
cart_model <- rpart(classdigit ~ npregnant + glucose + diastolic.bp +
skinfold.thickness + bmi + pedigree + age,
data = train_data, method = "class",
control = model.control)
# Compute test error for a single tree
my_pred_cart <- predict(cart_model, newdata = test_data, type = "class")
y_true_cart <- as.numeric(test_data$classdigit)-1
y_hat_cart <- as.numeric(my_pred_cart)-1
misclass_cart <- sum(abs(y_true_cart - y_hat_cart))/length(y_hat_cart)
misclass_cart # 0
rf.fit_importance <- importance(rf.fit)
top_vars <- rownames(rf.fit_importance)[order(-rf.fit_importance
[, "MeanDecreaseGini"])[1:2]]
pd_rf <- partial(rf.fit, pred.var = top_vars[1], grid.resolution = 20)
plotPartial(pd_rf, main = top_vars[1])
# For Boosting
summary(boost.fit)
# For CART
x11()
plot(cart_model)
text(cart_model, use.n = TRUE, cex = .5)
varImpPlot(rf.fit)
importance(rf.fit)
summary(rf.fit)
x11()
plot(cart_model)
text(cart_model, use.n = TRUE, cex = .5)
rm(list = ls())
setwd("C:\\Users\\acrot\\OneDrive\\Documents\\ADS-635")
library(rpart) # trees
library(gbm) # boosting
library(randomForest) # RF / bagging
data("spam.data")
library(ElemStatLearn)
install.packages("ElemStatLearn")
spam <- read.table("~/ADS-635/spam.data", quote="\"", comment.char="")
View(spam)
head(spam)
spam <- read.table("spam.data", header = FALSE)
head(spam)
# Split the data into training and test sets
set.seed(123)
train_indices <- sample(1:nrow(spam), nrow(spam)*0.7)
train_data <- spam[train_indices, ]
test_data <- spam[-train_indices, ]
# Extracting predictors and response
train_x <- train_data[, -58]
train_y <- train_data[, 58]
test_x <- test_data[, -58]
test_y <- test_data[, 58]
# Exploring a range of values for m
m_values <- seq(1, ncol(train_x), by = 5)
oob_errors <- numeric(length(m_values))
test_errors <- numeric(length(m_values))
for(i in 1:length(m_values)){
rf <- randomForest(x = train_x, y = train_y, mtry = m_values[i], ntree = 100)
# Storing OOB error
oob_errors[i] <- rf$err.rate[nrow(rf$err.rate), "OOB"]
# Predicting on test data and recording test error
preds <- predict(rf, newdata = test_x)
test_errors[i] <- mean(preds != test_y)
}
# Extracting predictors and response
train_x <- train_data[, -58]
train_y <- as.factor(train_data[, 58])
test_x <- test_data[, -58]
test_y <- as.factor(test_data[, 58])
# Exploring a range of values for m
m_values <- seq(1, ncol(train_x), by = 5)
oob_errors <- numeric(length(m_values))
test_errors <- numeric(length(m_values))
for(i in 1:length(m_values)){
rf <- randomForest(x = train_x, y = train_y, mtry = m_values[i], ntree = 100)
# Storing OOB error
oob_errors[i] <- rf$err.rate[nrow(rf$err.rate), "OOB"]
# Predicting on test data and recording test error
preds <- predict(rf, newdata = test_x)
test_errors[i] <- mean(preds != test_y)
}
# Plotting the results
plot(m_values, oob_errors, type = "l", col = "blue", ylim = c(min(c(oob_errors, test_errors)), max(c(oob_errors, test_errors))),
xlab = "Number of variables randomly selected at each split (m)", ylab = "Error Rate",
main = "OOB and Test Error Rates vs m")
lines(m_values, test_errors, col = "red")
legend("topright", legend = c("OOB Error", "Test Error"), fill = c("blue", "red"))
# Split the data into training and test sets
set.seed(123)
train_indices <- sample(1:nrow(spam), nrow(spam)*0.7)
train_data <- spam[train_indices, ]
test_data <- spam[-train_indices, ]
# Extract predictors and response
train_x <- train_data[, -58]
train_y <- as.factor(train_data[, 58])
test_x <- test_data[, -58]
test_y <- as.factor(test_data[, 58])
# Explore a range of values for m based on training data
m_values <- seq(1, ncol(train_x), by = 5)
oob_errors <- numeric(length(m_values))
test_errors <- numeric(length(m_values))
for(i in 1:length(m_values)){
# Create a random forest
rf <- randomForest(x = train_x, y = train_y, mtry = m_values[i], ntree = 100)
# Store OOB error
oob_errors[i] <- rf$err.rate[nrow(rf$err.rate), "OOB"]
# Predict on the test data and record the test error
preds <- predict(rf, newdata = test_x)
test_errors[i] <- mean(preds != test_y)
}
# Plot the results
plot(m_values, oob_errors, type = "l", col = "blue", ylim =
c(min(c(oob_errors, test_errors)), max(c(oob_errors, test_errors))),
xlab = "Number of Variables at Each Split m",
ylab = "Error Rate",
main = "OOB and Test Error Rates at m")
lines(m_values, test_errors, col = "red")
legend("topright", legend = c("OOB Error", "Test Error"), fill = c("blue", "red"))
spam_results
# Table of results
spam_results <- data.frame(
m = m_values, OOB_Error = oob_errors, Test_Error = test_errors)
spam_results
print(spam_results)
# Explore a range of values for m based on training data
m_values <- seq(1, ncol(train_x), by = 1)
oob_errors <- numeric(length(m_values))
test_errors <- numeric(length(m_values))
for(i in 1:length(m_values)){
# Create a random forest
rf <- randomForest(x = train_x, y = train_y, mtry = m_values[i], ntree = 100)
# Store OOB error
oob_errors[i] <- rf$err.rate[nrow(rf$err.rate), "OOB"]
# Predict on the test data and record the test error
preds <- predict(rf, newdata = test_x)
test_errors[i] <- mean(preds != test_y)
}
# Plot the results
plot(m_values, oob_errors, type = "l", col = "blue", ylim =
c(min(c(oob_errors, test_errors)), max(c(oob_errors, test_errors))),
xlab = "Number of Variables at Each Split m",
ylab = "Error Rate",
main = "OOB and Test Error Rates at m")
lines(m_values, test_errors, col = "red")
legend("topright", legend = c("OOB Error", "Test Error"), fill = c("blue", "red"))
# Table of results
spam_results <- data.frame(
m = m_values, OOB_Error = oob_errors, Test_Error = test_errors)
spam_results
# Explore a range of values for m based on training data
m_values <- seq(1, ncol(train_x), by = 3)
oob_errors <- numeric(length(m_values))
test_errors <- numeric(length(m_values))
for(i in 1:length(m_values)){
# Create a random forest
rf <- randomForest(x = train_x, y = train_y, mtry = m_values[i], ntree = 100)
# Store OOB error
oob_errors[i] <- rf$err.rate[nrow(rf$err.rate), "OOB"]
# Predict on the test data and record the test error
preds <- predict(rf, newdata = test_x)
test_errors[i] <- mean(preds != test_y)
}
# Explore a range of values for m based on training data
m_values <- seq(1, ncol(train_x), by = 5)
oob_errors <- numeric(length(m_values))
test_errors <- numeric(length(m_values))
for(i in 1:length(m_values)){
# Create a random forest
rf <- randomForest(x = train_x, y = train_y, mtry = m_values[i], ntree = 100)
# Store OOB error
oob_errors[i] <- rf$err.rate[nrow(rf$err.rate), "OOB"]
# Predict on the test data and record the test error
preds <- predict(rf, newdata = test_x)
test_errors[i] <- mean(preds != test_y)
}
# Plot the results
plot(m_values, oob_errors, type = "l", col = "blue", ylim =
c(min(c(oob_errors, test_errors)), max(c(oob_errors, test_errors))),
xlab = "Number of Variables at Each Split m",
ylab = "Error Rate",
main = "OOB and Test Error Rates at m")
lines(m_values, test_errors, col = "red")
legend("topright", legend = c("OOB Error", "Test Error"), fill = c("blue", "red"))
# Table of results
spam_results <- data.frame(
m = m_values, OOB_Error = oob_errors, Test_Error = test_errors)
spam_results
